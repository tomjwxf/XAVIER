import json, glob, os, io, zipfile
import pandas as pd
import numpy as np
import streamlit as st

st.set_page_config(page_title="XAVIER Receipts KPIs", layout="wide")
st.title("XAVIER Receipts KPIs (MVP)")

folder = st.sidebar.text_input("Receipts folder", "test_vectors")
schema_path = st.sidebar.text_input("Schema path", "receipt.schema.json")
pubkeys_path = st.sidebar.text_input("Pubkeys (optional)", "pubkeys.json")

paths = sorted(glob.glob(os.path.join(folder, "*.json")))
rows = []
for p in paths:
    try:
        with open(p, "r", encoding="utf-8") as f:
            r = json.load(f)
        em_ms = r.get("receipt_emission_ms")
        # Backfill emission_ms from timestamps if missing
        if em_ms is None:
            try:
                from datetime import datetime
                fin = datetime.fromisoformat(r["timestamps"]["finality_at"].replace("Z","+00:00"))
                emt = datetime.fromisoformat(r["timestamps"]["receipt_emitted_at"].replace("Z","+00:00"))
                em_ms = int((emt - fin).total_seconds() * 1000)
            except Exception:
                em_ms = None
        rows.append({
            "file": os.path.basename(p),
            "receipt_emission_ms": em_ms,
            "incident_code": r.get("incident_code"),
            "corridor": r.get("corridor"),
        })
    except Exception as e:
        rows.append({"file": os.path.basename(p), "error": str(e)})

df = pd.DataFrame(rows)
st.write(f"Loaded {len(df)} receipts")

col1, col2, col3 = st.columns(3)
if not df.empty:
    ok_mask = df["incident_code"].isna() | df["incident_code"].eq(None)
    coverage = float(ok_mask.mean()*100) if len(df)>0 else 0.0
    with col1:
        st.metric("Coverage (no incident_code)", f"{coverage:.1f}%")
    em_series = df["receipt_emission_ms"].dropna()
    if len(em_series) > 0:
        p95 = int(np.percentile(em_series, 95))
        with col2:
            st.metric("p95 Receipt Emission (ms)", f"{p95}")
        st.subheader("Receipt Emission Histogram (ms)")
        st.bar_chart(em_series)

    with col3:
        st.metric("Receipts with emission_ms", f"{em_series.count()}/{len(df)}")

    st.subheader("Incidents by Code")
    if df["incident_code"].notna().any():
        st.dataframe(df["incident_code"].value_counts().rename_axis("incident_code").to_frame("count"))
    else:
        st.write("No incidents recorded in this set.")

st.subheader("Receipts Table")
st.dataframe(df)

# Build in-memory Auditor Pack zip
def build_auditor_pack():
    mem = io.BytesIO()
    with zipfile.ZipFile(mem, "w", compression=zipfile.ZIP_DEFLATED) as z:
        # Add receipts
        for p in paths:
            z.write(p, arcname=os.path.join("test_vectors", os.path.basename(p)))
        # Add schema
        if os.path.exists(schema_path):
            z.write(schema_path, arcname="receipt.schema.json")
        # Add pubkeys if present
        if os.path.exists(pubkeys_path):
            z.write(pubkeys_path, arcname="pubkeys.json")
        # Add README
        readme = """Auditor Pack
- Receipt schema: receipt.schema.json
- Public keys: pubkeys.json (if present)
- Receipts: test_vectors/*.json
Verification:
1) pip install -r requirements.txt
2) python verify.py --path test_vectors --skip-sig
3) Or verify signatures (if signed): python verify.py --path test_vectors --pubkeys-file pubkeys.json
"""
        z.writestr("README_AUDIT.txt", readme)
    mem.seek(0)
    return mem.getvalue()

st.download_button(
    "Download Auditor Pack (zip)",
    data=build_auditor_pack(),
    file_name="auditor-pack.zip",
    mime="application/zip"
)
